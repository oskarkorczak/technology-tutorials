# sbt Tutorial
Sbt mechanics and basic application setup from scratch till open sourcing stage.

## sbt shell
Below commands are executed after invoking `sbt` in Bash shell. 

### Basic sbt startup
Create project root direcotry with empty `build.sbt` and run SBT shell in project root directory, as below:

```
mkdir sbt101
cd sbt101
touch build.sbt
sbt
```

What happens during SBT startup:

1. sets sbt version in `./sbt101/project/build.properties`, so that every other run can use the same sbt version (it is fetched if non-existent)
2. sbt loads global plugins from `~/.sbt/1.0/plugings`, if they exist
3. sbt loads project definition from `./sbt101/project` folder, which may contain some other Scala code that may be used in your project
4. sbt loads settings from `./sbt101/build.sbt` file (atm file is empty ergo nothing should be loaded)
5. sbt picks direcotry path as the project name and sets it (since `build.sbt` is empty and there is no specific project name assignment)


### Help

`scalaVersion` - yields Scala version
`help` - shows all available commands, settings and tasks
`help compile` - shows what `compile` does
`help tasks` - shows what `tasks` do


### Run
```
cd sbt101
mkdir -p src/main/scala
vim src/main/scala/HelloWorld.scala
```

#### Single executable classes
Write simple HelloWorld application:

```
object HelloWorld extends App {
	println("Hello sbt!")
}
```

`compile` - compiles source file(s)

`run` - run executable class (extending `App`). Actually it first creates jar and then runs it.

#### Two executable classes

Write another simple class:

```
object Echo extends App {
	println(s"You said: ${if (args.isEmpty) "nothing" else args.mkString(" ")}")
}
```

Then run below command:

`run A B C` - sbt first compiles new class, detected multiple runnable classes and without making any assumptions it asked which one to run. 


### Chaining
`;clean ;compile` - chaining many tasks inside sbt


### History
`!` - access list of history related commands executed earlier


### Scala console (REPL)
`console` - it compiles project source files and gives Scala console ready for experimenting with project classes, before making them part of the project

#### Run
`Echo.main(Array("A", "B", "C"))` - runs one of the executable classes written earlier


### Exit
`:q` - exit Scala console 

`exit` - exit sbt



## Bash shell
Below commands are executed straight from Bash shell. 
However, when running sbt from Bash level, sbt reguires **every time** JVM and JIT spin up. Therefore it will be always slower than running commans from inside of sbt. 

### Chaining
`sbt clean compile` - chaining sbt commands

### Run
`sbt "run A B C"` - Passing Scala app arguments to the class using sbt  command from Bash shell level



## Directories structure
Structure of sbt comprehandable directories.

### Structure overview
```
sbt101/										// baseDirectory

	src/										// sourceDirectories (source files outside of src/ are ignored, hidden files too)
		main/
			scala/
			java/
	
			resources/						// resourceDirectories (resources used in application)
			
		test/									// test:sourceDirectories (all tests sit here)
			scala/
			java/
			
			resources/						// test:resourceDirectories (resources used in testing)
			
		build.sbt 							// build definition (all settings needed to build the project)
		
		project/								// build support files (may include other scala, sbt files needed to build the project)
			build.properties
			# more scala, *.sbt files
			
		target/								// target (artifacts generated by sbt including classes, jars and others)
```

### sbt shell
Run `sbt` in command line to open up sbt shell.

#### Tab based completion
`Tab` key gives hints what settings exits with given prefix say `source <<Tab key>>` (same as in Linux)

#### settings
`baseDirectory` - path to base/root direcotry where Scala project is located

`sourceDirectory` - shows where sbt looks for source files for compilation

`scalaSource` - where Scala finds source files

`target` - where artifacts are generated
 


## Build definition syntax & settings
Build definition is the name of `build.sbt` file. 

Relevant commands and settings for `build.sbt` file. 
All below commands are to be written in `build.sbt` file. 

### Reload
`reload` - refreshes the project based on current directory. Every change in `build.sbt` file has to be reloaded, so that sbt can see it.
It is convenient to run `;reload ;name` so that reload always happens.

### Project name
`name := "sbt201"` - defines project name in `build.sbt` file

In sbt console invoke `name`. It should give correct value of `sbt201` given the `build.sbt` was reloaded. 

#### Syntax
In sbt project is configured by key-value pairs. 
The syntax in divided in to three parts: key, separator (separates key from the body) and body.  

### Expression key types
| Key            | Purpose                        |
| :------------: |:------------------------------:|
| SettingKey[T]  | Computed once per project load |
| TaskKey[T]     | Recomputed every time called   |
| InputKey[T]    | Accepts command line arguments |

`T` represents the type of the value it holds. It could be derived from `inspect` command run in sbt shell. 

`inspect name` - `<<name>>` represents key from `build.sbt` file. First line defines type `T` of the `name` key and also is prefixes with expression type. In this example it is equal to `setting`, indicating it is SettingKey. Run in sbt shell. 

#### Setting Expression
`inspect name`

| key    | separator | body   | key type `T`     |
| :----: |:---------:| :-----:| :--------------: |
| name   | :=        | sbt201 | java.lang.String |
`:=` assignment operator


#### Task Expression
`inspect package` or `inspect clean` 

| key       |  key type `T` |
| :-------: | :------------:|
| package   | java.io.File  |
| clean     | Unit          |

#### Input Expression
`inspect run`

| key   | key type `T` |
| :---: | :-----------:|
| run   | Unit         |


### Built-in keys
Every `build.sbt` file implicitely imports predefined set of keys  `import sbt.Keys._`. 
That is why it was possible for us to use `name` in `build.sbt`, as it has already been defined. 

#### Implicit keys docs
More details on implicitely imported, buit-in keys could be found in sbt docs.  

#### sbt shell
`settings` - list of setting keys available in sbt project, but not all of them

`settings -V` - full list of setting keys available in sbt project

`tasks` - list of task keys available in sbt project

`tasks -V` - full list of task keys available in sbt project


### Custom keys
Custom keys could be added to `build.sbt` file. Adding them is split into two steps: Define & Use. 

There are three creation methods: `settingKey[T]`, `taskKey[T]` or `inputKey[T]`. Notice lowercase `s`, `t` & `i` for those methods. 


#### Custom setting
In `build.sbt` file write:

```
lazy val emotion = settingKey[String]("How are you feeling")
emotion := "Fantastic"
```
- `emotion` - key name
- `val` - immutable
- `lazy` - avoid initialization order problems, where setting is used before it was declared
- `String` - key value type
- `"How are you feeling"` - key description used when `help` or `inspect` commands are run

Then `reload` the project and run `help emotion`, `inspect emotion` & `emotion`. Run it few times. It shows that the setting is fixed across reload of the `build.sbt` file. 

#### Custom task
In `build.sbt` file write:

```
val randomInt = taskKey[Int]("Give me random number")
emotion := scala.util.Random.nextInt
```

Then `reload` the project and run `help randomInt `, `inspect randomInt ` and `randomInt `. There is no output even though the task was run. In order to see the output of the task on the console use `show randomInt` command. Check the output few times to confirm that randomizer works. It also confirms that task is executed every time it is run. 


#### Custom input
It is a bit more involved process and requires understanding of parser combinators. Used rather rarely. 



## Expression dependencies
`Settings` may depend on other settings. `Tasks` may depend on other tasks and settings. However, `settings` **cannot** depend on other `tasks`. The reason is that by definition:
- `settings` are computed once per project load
- `tasks` are recomputed every time they are called

If `settings` were dependent on `tasks`, they could fail as by definition `settings` should be invariant and cannot change, whereas `tasks` could. 

### Setting depending on another setting
In `build.sbt` file write:

```
lazy val emotion = settingKey[String]("How are you feeling")
emotion := "Fantastic"

val status = settingKey[String]("What is your current status?")
status := {
	val e = emotion.value
	s"Grateful and $e"
}
```

- `status` defined dependency on emotion using `*.value`. This is how dependencies are defined in build definition
- `$e` value used for implementation

All dependent settings are evaluated before and in no particular order, before the task or settings which has dependencies on itself could be interpreted.

Then `reload` the project and run `status`. Also run `inspect status` to see dependencies.

### Task depending on setting
In `build.sbt` file write:

```
lazy val emotion = settingKey[String]("How are you feeling")
emotion := "Fantastic"

val randomInt = taskKey[Int]("Give me random number")
randomInt := {
        println(emotion.value)
        scala.util.Random.nextInt
}
```

Then `reload` the project and run `show randomInt` few times. The settings related part is fixed and task related portion is changing. Also run `inspect randomInt` to see dependencies.


### Task depending on another task
In `build.sbt` file write:

```
lazy val randomInt = taskKey[Int]("Give me random number")
randomInt := scala.util.Random.nextInt

val randomPlus = taskKey[Int]("Adds one to random number")
randomPlus := {
        val num = randomInt.value
        println(s"$num")
        num + 1
}
```

Then `reload` the project and run `show randomInt` few times, then run `show randomPlus` few times, as well . Also run `inspect randomPlus` to see dependencies and compare it to `inspect randomPlus`.


### Setting depending on task - failure
In `build.sbt` file write:

```
lazy val randomInt = taskKey[Int]("Give me random number")
randomInt := scala.util.Random.nextInt

val status = settingKey[String]("What is your current status?")
status := {
	val r = randomInt.value
	s"Grateful and $r"
}
```

Then `reload` the project. Sbt does not like setting depending on task and **fails** with below message:

```
error: A setting cannot depend on a task
	val r = randomInt.value
                ^
[error] Type error in expression
```



## Project lifecycle
Goal: I want to deliver project called *Calculators*, containing all calculators, which we plan to ship as a separate jar.

In sbt top level direcotry (root direcotry) is called *Project*. Any project located underneath root project is called *sub-project*. 

```
Project sbt-getting-started			(root direcotry)
	Sub-project calculators			(sub-project containing Scala calculators)
```

### Creating projects & sub-projects
In `build.sbt` file write:

```
val root = project.in(file("."))
val calculators = project
```

There are two (sub)projects created here:

- `root` - the project and sits in the top level sbt direcotry
- `calculators` - the sub-project of root project and sits inside top level sbt direcotry

`project` - the keyword used to define sbt sub-project. There are two ways of using this command:

1. `val calculators = project` in which case sbt does:

	* create directory called *calculators* in top level project
	* makes sub-project name reference `calculators` available for build definition for further use
	
2. `val root = project.in(file("."))` using `project` and `in()` method pointing that *root* sits in top level directory

Add below sample, calculator Scala code file under `./calculators/src/main/scala/NetWorth.scala` path. 

```
object NetWorth extends App {
	def calculate(assets: Long, liabilities: Long): Long = assets - liabilities
	
	override def main(args: Array[String]): Unit = {
		val assets = args(0).toLong
		val liabilities = args(1).toLong
		println(s"Your net worth is ${calculate(assets, libilities)}")
	}
}
```

Reload and compile whole setup by issuing: `;reload ;compile`.
Newly added Scala calculators code did not get compiled because `calculators` project was not selected by sbt. `compile` was only run against selected sub-project ie `root`. Since, `root` has no code, there was no compilation.

*Read below for more explanation.*


### Projects management
`projects` shows all defined sub-projects in current sbt project. Sample output:

```
[info]		calculators
[info]    * root
```
`*` denotes selected sub-project by sbt

#### Compile sources in the sub-project
There are three ways of compiling sources in the sub-project. However, compiling is just a command used as an exmaple. Equally, it could be `clean` or `run` or whatever is convenient at given time:

##### Sub-project specific command
`calculators/compile` run sub-project specific command from `root` project level

##### Switch to relevant sub-project
switch to `calculators` project and run `compile` command:

```
project calculators
;clean ;compile
```

`project calculators` switch to `calculators` sub-project and make it current sub-project. It also enriched sbt prompt to show which sub-project one is in. 

`;clean ;compile` worked only on `calculators` project, as this is current project

By running `projects` command it could be confirmed that current project is set to `calculators`:

```
[info]	  * calculators
[info]    root
```

##### Relationship between sub-projects
Does not require switching or selecting sub-projects manually. 

So far there are two sub-projects in build definition file: `root` (at the top level sbt direcotry) and `calculators` (sub-project under the `root`). 

We may define the relationship between above two projects by making `root` the *aggregator* of the sub-project(s). In this way, we make sure that any command issues to `root` is broadcasted to all, aggregated sub-projects.


```
val root = project.in(file("."))
	.aggregate(calculators)
val calculators = project
```

Switch to `root` project and reload the settings:

```
project root
reload
```

It fails saying it cannot find the reference to uninitialized calculators sub-project. It is because we used `calcualators` reference before it was even initialized. Use lazy laoding to fix the issue. 

```
lazy val root = project.in(file("."))
	.aggregate(calculators)
lazy val calculators = project
```

Relaod projects, switch project to `root` (check it with `projects`) and `;clean ;compile`. Now the Scala calculator class was compiled. 


#### Run application in the sub-project
Go to `root` sub-project and execute `;clean ;run`. It does not run the executable class, as `run` command only tries to search for runnable code in the current sub-project. In this case current sub-project does not have anything to run. 

Use any method to switch to `calculators` and run `;clean ;run` again. This time it works.





## Expression key scope
Before key scopes are introduced there has to be problem laid down to set the context. 

### Problem statement
Just for ilustration purposes, if the executable Scala class (the one extending `App`) is added in `./src/test/scala/NetWortSpec.scala` and there is no unit test framework (naive approach), then tests have to be run by invoking `NetWorthSpec.scala` class manually. 

Executable test class body:

```
object NetWorthSpec extends App {
	def runTests(): Unit = {
		assert(NetWorth.calculate(100, 20) == 80, "the result should be 80")
		assert(NetWorth.calculate(1000, 2000) == -1000, "the result should be -1000")
	}
	
	override def main(args: Array[String]): Unit = {
		println("Running tests ...")
		runTests()
		println("All tests passed.")
	}
}
```

Try running above class by invoking: `calculators/run`.

This approach would fail, as above comamnd invokes `./src/main/scala/NetWorth.scala` executable class. What's more it fails due to lack of arguments provided.


### Expression keys

Keys are not available in the flat structure (like map). Instead they are identified by the scope they are in. 

`Key` is defined by three variables (aka `scope axis`). In mathematical terms it is a function `key = f(x, y, z)`. 

### Scope axis
There are three scope axis in sbt: 

* `project` aka sub-project in sbt defined in sbt build definition file. Many projects are aka multimodules in sbt e.g.: `api`, `business`, `database` 
* `config` is the context of the build; the most common values are: `Compile`, `Test`, `Runtime` (capital letter is important)
* `task` is a function in build definition file that executes every time it is called e.g.: `run`, `package`, `clean`

Overall formula for deriving `key`:
`key = f(project, config, task)`

### Sensible defaults
The only required thing to find out the value of the `key` is key. By specifing what the key is, you get the corresponding value back, if it exists. Otherwise, you get an error. 

None of the scope axis are reuired and they are all optional. 

| Project   | Config    | Task      | Key       |
| :-------: | :-------: | :-------: | :-------: |
| optional  | optional  | optional  | required  |

`proejct` - current project is taken, if no project scop axis is provided

`config` - sbt searches for `key` in `Compile` and then `Test` scope in this order. If it finds match, the search is stopped and no further look ups are executed. 

`task` - it only searches for the `key` if the task is provided, else it makes no search in this scope axis


### Problem statment resolution
`calculators/run` tried to run `./src/main/scala/NetWorth.scala` class and failed with error complaining for lack of arguments passed to the class. 

Executed command was: `calculators/run`, where:

* `run` is the `Task Key` we intended to run
* `calculators` is the `Project Axis`, which was pointed explicitely

No other scope axis was selected, so sbt falled back to its sensible defaults described above. For `Config Axis` it started to go through `Compile` and then `Test`. It found `Compile` and started to execute `run` in that context, which is `./src/main/scala`

Correct command `calculators/Test/run` works fine, now.

#### Resolving key scope
`inspect` helps to resolve the key context, by running for example: `inspect calculators/run`. The `Provided by:` section expands precisely the whole context of the command to: `... "calculators") / Compile / run`, which is very helpful. 



## Running particular executable classes
Let's assume there is one more calculator in the `./src/main/scala/CompoundInterest.scala` package. 

If you want to run executable Scala classes in `./src/main/scala` then you may define which class you have in mind. It could be done by invoking command: `calculators/runMain CompoundInterest 5000 5 10`.



## External libraries
Sub-project called `calculators` is designed to do the actual calculations on given data (idea of service layer). However, in order to open this Scala project to external world, there is a need of decent entry point ie `api`. 

```
lazy val calculators = project
lazy val api = project
	.settings(
		libraryDependencies ++= Seq(
			"com.lihaoyi" %% "requests" % "0.1.7",
			"org.scala-lang.modules" %% "scala-xml" % "1.1.1",
			"org.scalatest" %% "scalatest" % "3.0.5" % Test
		)
	)
```

`project.settings()` - means these are exclusive settings for `api` project only and they will not be used anywhere else. 

`libraryDependencies` - a setting which actually is a sequence holding dependencies. Also, these dependencies will be downloaded for given sub-project. 

`"org.scalatest" %% "scalatest" % "3.0.5" % Test` - entire line is called *ModuleID*, where:

* `"org.scalatest"` - organisation
* `"scalatest"` - name of the library
* `"3.0.5"` - version
* `Test` - configuration


### Testing
There could be tests written for both `api` and `calculators` sub-projects. That would require adding `"org.scalatest" %% "scalatest" % "3.0.5" % Test` to both sub-projects:

```
lazy val calculators = project
	.settings(
		libraryDependencies += ("org.scalatest" %% "scalatest" % "3.0.5" % Test)
	)

lazy val api = project
	.settings(
		libraryDependencies ++= Seq(
			"com.lihaoyi" %% "requests" % "0.1.7",
			"org.scala-lang.modules" %% "scala-xml" % "1.1.1",
			"org.scalatest" %% "scalatest" % "3.0.5" % Test
		)
	)
```

Now, there could be one `test` command run from sbt shell and it will be propagated to both sub-projects for further execution. 

#### Parallel execution
In sbt all tests are run in *parralel*. It could be verified by running `Test/parallelExecution` command. It yields below result:

```
[info]	api / Test / parallelExecution
[info]	true
[info]	calculators / Test / parallelExecution
[info]	true
[info]	Test / parallelExecution
[info]	true
```

#### Triggered execution
`~<<sbt-command>>` is so called *triggered execution* comamnd in sbt. It allows to continuously search for relevant changes in `<<sbt-command>>` input and trigger the `<<sbt-command>>`, when change is discovered. `~` could be applied to **any** sbt command. 

It is very similar to Linux `watch <<command>`. 

Triggered execution could be utilised for running tests in continuous loop in sbt. By invoking `~test` sbt runs `test` command and keeps on watching for any changes in test files. This way there is continuous feedback loop for tests. 


### Libraries duplication
It is rather hard to maintain many dependencies for each sub-project, keeping them up to date and same time avoiding duplication e.g.: testing lib:

```
lazy val calculators = project
	.settings(
		libraryDependencies += ("org.scalatest" %% "scalatest" % "3.0.5" % Test)
	)

lazy val api = project
	.settings(
		libraryDependencies ++= Seq(
			"com.lihaoyi" %% "requests" % "0.1.7",
			"org.scala-lang.modules" %% "scala-xml" % "1.1.1",
			"org.scalatest" %% "scalatest" % "3.0.5" % Test
		)
	)
```

#### Extracting dependencies to project folder
In `./project` direcotry, we have added new file called `Dependencies.scala`, which is an `object`

```
import sbt._

object Dependencies {
	
	val scalaRequests = "com.lihaoyi" %% "requests" % "0.1.7",
	val scalaXml = "org.scala-lang.modules" %% "scala-xml" % "1.1.1"
	val scalaTest = "org.scalatest" %% "scalatest" % "3.0.5"
	
	val commonDependencies: Seq[ModuleID] = Seq(scalaTest % Test)
	
	val apiDependencies: Seq[ModuleID] = Seq(scalaRequests, scalaXml) ++ commonDependencies
	
	val calculatorDependencies: Seq[ModuleID] = commonDependencies


}
```

Then in build definition `build.sbt`, dependencies are replaced with below code:

```
lazy val calculators = project
	.settings(
		libraryDependencies ++= Dependencies.calculatorDependencies
	)

lazy val api = project
	.settings(
		libraryDependencies ++= Dependencies.apiDependencies
	)
```
Now, all the dependencies could be managed without touching `build.sbt` file. 



## Sub-projects relationships
The plan is to have `calculators` sub-project depending on `api` one. It is achieved by adding `.dependOn(api)` in `calculators` sub-project.

This way sbt keeps track on changes done to `api` and making them available to `calculators`. 
In other words, `calculators` needed `api` project on its **classpath**. 

```
name := "sbt-getting-started"
version := "0.1"
scalaVersion := "2.12.8"

lazy val calculators = project
	.dependsOn(api)
	.settings(
		libraryDependencies ++= Dependencies.calculatorDependencies
	)

lazy val api = project
	.settings(
		libraryDependencies ++= Dependencies.apiDependencies
	)
```


## Packaging
Sbt native packager will be used for that purpose. 

### Plugins
Plugin extends build definition `build.sbt` by adding new settings. 

In `./project/plugins.sbt` add `sbt-native-packager`:

```
addSbtPlugin("com.typesafe.sbt" % "sbt-native-packager" % "1.3.21")
```

### Java packaging
Then in `build.sbt` add:

```
import com.typesafe.sbt.packager.docker.ExecCmd

name := "sbt-getting-started"
version := "0.1"
scalaVersion := "2.12.8"

lazy val calculators = project
	.dependsOn(api)
	.enablePlugins(JavaAppPackaging)
	.enablePlugins(DockerPlugin)
	.settings(
		libraryDependencies ++= Dependencies.calculatorDependencies,
		dockerCommands := dockerCommands.value.filternot {
			case ExecCmd("ENTRYPOINT", _) => true
			case _ => false
		},
		dockerCommands ++= Seq(ExecCmd("ENTRYPOINT", "/opt/docker/bin/net-worth"))
	)

lazy val api = project
	.enablePlugins(JavaAppPackaging)
	.settings(
		libraryDependencies ++= Dependencies.apiDependencies
	)
```
The most important part is enabling Java style `sbt-native-packager` in both sub-projects by adding: `.enablePlugins(JavaAppPackaging)`. 

Run `stage` command. It is a task provided by `sbt-native-packager` and it creates jar files for sub-projects. Jar files are located in relevant sub-project's `target` folders:

* `./calculators/target/scala-2.12/`
* `./api/target/scala-2.12/`

`stage` also creates binaries so that applications could be run:

* `./calculators/target/universal/stage/bin/net-worth 100 200`
* `./calculators/target/universal/stage/bin/compound-interest 5000 5 10`
* `./api/target/universal/stage/bin/compound-interest 5000 5 10`


### Docker packaging
`sbt-native-packager` can create Docker images for the project. The only requirement is that you **must** have Docker installed on your machine.

Once downloaded and installed make sure it is running by invoking `docker -v` command. 

Then in build definition `build.sbt` file Docker has to be enabled by adding `.enablePlugins(DockerPlugin)` in `calculators` project. Also, since there are many main classes, Docker needs to know which binary is the entry point for Docker container. This is done by:

```
dockerCommands := dockerCommands.value.filternot {
			case ExecCmd("ENTRYPOINT", _) => true
			case _ => false
		},
		dockerCommands ++= Seq(ExecCmd("ENTRYPOINT", "/opt/docker/bin/net-worth"))
```

In sbt shell run `docker:publishLocal` command, which will kick off the Docker image creation. You may see the picked entry point in the logs. 

**BTW** There is a bit of confusion why we need to use `docker:` prefix. It comes from the fact that the `publishLocal` is the sbt task publishing assets to local Ivy/Maven repository. The Docker support  in `sbt-native-packager` tries to use the same task in a Docker context, so that `sbt docker:publishLocal` builds an image on your local Docker server. Just like publishing to Ivy or Maven locally, this action allows the image to be visible locally for develop ment, but does not make it visible outside your local machine.
**Probably** in newer versions of sbt (1.1) the new *unified slash syntax* could be used, where the `docker` scope would be `Docker`, so `docker:publishLocal` would become `Docker / publishLocal`.

Run `docker images` for validating, if `calculators` are having image created. 

Further, `calculators` could be validated by running Docker image `docker run -it calculators:0.1.0-SNAPSHOT 100 20`.
 


## Continuous integration
TravisCI will be used, because it is free for open-source projects and integrates well with GitHub. 

There has to be a `./.travis.yml` file dropped in to the project:

```
language: scala
scala:
	- 2.12.8

```

Since it is sbt project, Travis picks it up automatically (see Travis manual page). Additionally, project could be buit against many versions of Scala, but this is the minimum, necessary setup. 

Sign up to TravisCI using GitHub credentials, sync accounts and activate repository. Go to `settings -> more options` and trigger the build. 



## Open-sourcing project
Open-sourcing the project via Bintray.

Set up open source account using GitHub credentials, authorise bintray-bot. Add new repository (e.g.: maven type) and follow the wizard. 

Another thing is setting up keys. Go to your profile: `edit profile => API Key => copy API key`. It is necessary to have this API key, while publishing packages to Bintray. 

### Configure build definition to push to Bintray
In `./project/plugins.sbt` add another plugin `addSbtPlugin("org.foundweekends" % "sbt-bintray" % "0.5.4")`.

Now, there have to be few changes in `build.sbt` file:

```
import com.typesafe.sbt.packager.docker.ExecCmd

name := "sbt-getting-started"
ThisBuild / version := "1.0"
scalaVersion := "2.12.8"
ThisBuild / licenses ++= Seq(("MIT", url("http://opensource.org/licenses/MIT")))
publish/skip := true

lazy val calculators = project
	.dependsOn(api)
	.enablePlugins(JavaAppPackaging)
	.enablePlugins(DockerPlugin)
	.settings(
		libraryDependencies ++= Dependencies.calculatorDependencies,
		dockerCommands := dockerCommands.value.filternot {
			case ExecCmd("ENTRYPOINT", _) => true
			case _ => false
		},
		dockerCommands ++= Seq(ExecCmd("ENTRYPOINT", "/opt/docker/bin/net-worth"))
	)

lazy val api = project
	.enablePlugins(JavaAppPackaging)
	.settings(
		libraryDependencies ++= Dependencies.apiDependencies
	)
```

* `ThisBuild / version := "1.0"` updated version of the project, Bintry does not allow deploying snapshots or not released builds
* `ThisBuild / licenses ++= Seq(("MIT", url("http://opensource.org/licenses/MIT")))` build definition must have license added
* `publish/skip` is `true` for `root` project, so that `root` project is not published (`root` is basically ignored publishing-wise)

`ThisBuild` refers to `build level` settings for the project. It means that sbt has a three stage fall back strategy for settings:

* `sub-project level`- first sbt checks, whether given sub-project ie `calculators` or `api` has sub-project level settings. If found it picks the value
* if not sbt falls back to `build level` settings (referred as `ThisBuild`) and if value exists it picks the value
* if not it falls back to `global settings`

### Versioning

If `ThisBuild` is not added to `version` setting in `build.sbt` file, then it is applied only on a `root` sbt project level. So, if no `ThisBuild` is there and `build.sbt` is reloaded the version check shows below:

`;reload ;version` produces:

```
[info] api / version
[info] 0.1.0-SNAPSHOT
[info] calculators / version
[info] 0.1.0-SNAPSHOT
[info] version
[info] 1.0
```

Whereas, if `ThisBuild` is added to `version` setting in `build.sbt` there is consistent versioning across sub-projects and `root` project. It also means that Bintray will allow pushing those artifacts. See below:

`;reload ;version` produces:

```
[info] api / version
[info] 1.0
[info] calculators / version
[info] 1.0
[info] version
[info] 1.0
```

### Login to Bintray
In sbt console type `bintrayChangeCredentials` and pass Bintray username x3 times and API key also x3 times. Then hit the `reload` and you are all set. 

### Publish

Then `;clean ;publish` which cleans the build and publishes to Bintray. Go to Bintray and double check that both `api` and `calcualtors` are there. 

The other way to confirm correct publish is to add another sub-project which depends on `calculators`. In `build.sbt` add:

```
resolvers += Resolver.JCenterRepository
lazy val test = project.settings(
	libraryDependencies += ("calculators" % "calculators_2.12" % "1.0")
)
```
`resolvers += Resolver.JCenterRepository` - points resolver to JCenter where packages are hosted. Then new project is added with `calculators` dependencies. Run `;reload ;update` to fetch all dependencies. 
